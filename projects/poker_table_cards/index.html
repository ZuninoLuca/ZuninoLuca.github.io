<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Poker table cards and chips recognition | Luca Zunino </title> <meta name="author" content="Luca Zunino"> <meta name="description" content="Final project for the EPFL course " image analysis pattern recognition> <meta name="keywords" content="luca, zunino, luca-zunino, machine-learning, robotics, research, engineer, portfolio"> <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"> <meta http-equiv="Pragma" content="no-cache"> <meta http-equiv="Expires" content="0"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zuninoluca.github.io/projects/poker_table_cards/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Luca</span> Zunino </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Poker table cards and chips recognition</h1> <p class="post-description">Final project for the EPFL course "Image Analysis &amp; Pattern Recognition"</p> </header> <article> <div class="row justify-content-center mt-1 mb-4"> <div class="col-sm-2 col-4 text-center"> <a href="/assets/pdf/Presentation.pdf" class="btn btn-sm btn-outline-primary" target="_blank"> <i class="fa-solid fa-desktop"></i> Slides </a> </div> <div class="col-sm-2 col-4 text-center"> <a href="https://github.com/ZuninoLuca/Image_analysis_and_pattern_recognition" class="btn btn-sm btn-outline-primary" target="_blank" rel="external nofollow noopener"> <i class="fab fa-github"></i> Code </a> </div> </div> <h2 id="at-a-glance">At a glance</h2> <p>Final project for the EPFL course <strong>“Image Analysis and Pattern Recognition”</strong> (Prof. J.-P. Thiran), completed in <strong>Spring 2022</strong> with <strong>Roberto Minini</strong> and <strong>Roberto Ceraolo</strong>.</p> <p>We implemented <strong>an end-to-end image understanding task</strong> on poker-table scenes. Starting from a single RGB image of a table, our system automatically identifies:</p> <ul> <li>The <strong>five table cards</strong>,</li> <li>The <strong>two cards of each player</strong> (or detects <strong>face-down</strong> / absent players),</li> <li>The <strong>number of chips per color</strong> in the pot.</li> </ul> <div class="row justify-content-center"> <div class="col-sm-6 mx-auto mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_covers/IAPR_table-480.webp 480w,/assets/img/project_covers/IAPR_table-800.webp 800w,/assets/img/project_covers/IAPR_table-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/project_covers/IAPR_table.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Poker-table scene to be analyzed" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Our system transforms a single poker-table snapshot into structured game state: every card identified, every chip counted. </div> <hr> <h2 id="approach-overview">Approach overview</h2> <p>We implemented a robust <strong>classical computer vision pipeline</strong> that turns a complex image into structured predictions through staged geometry + detection + classification:</p> <ol> <li> <strong>Detect table corners</strong> in the original image</li> <li> <strong>Warp</strong> the image to obtain a frontal view of the table</li> <li> <strong>Split</strong> the warped table into semantic regions (players / table cards / chips)</li> <li> <strong>Detect + classify chips</strong> (circle detection + color-based k-NN)</li> <li> <strong>Recognize cards</strong> (template matching with rotation search)</li> <li> <strong>Return predictions</strong> in the required dictionary format</li> </ol> <p>A key design choice was to increase robustness by combining <strong>redundant preprocessing hypotheses</strong> (multiple thresholding methods + voting) with <strong>simple but reliable classifiers</strong> (k-NN on color features; template matching for symbols).</p> <hr> <h2 id="1-table-extraction-corner-detection">1) Table extraction (corner detection)</h2> <div class="row justify-content-center"> <div class="col-sm-12 mx-auto mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/IAPR/IAPR_1-480.webp 480w,/assets/img/projects/IAPR/IAPR_1-800.webp 800w,/assets/img/projects/IAPR/IAPR_1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/IAPR/IAPR_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Step 1 of our approach (table extraction)" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The first step of our pipeline localizes the table corners to isolate the playing surface from the surrounding scene. </div> <h3 id="core-idea">Core idea</h3> <p>Accurate recognition becomes much easier once the table is isolated and rectified. We therefore detect the table as the dominant object and estimate its four corners.</p> <h3 id="what-we-did">What we did</h3> <ul> <li>Convert the image to <strong>LAB</strong>, using the <strong>L channel</strong> as grayscale.</li> <li> <strong>Downscale</strong> the image to a tractable resolution (e.g., 200×300) for faster processing.</li> <li>Compute <strong>five different binary masks</strong> using multiple thresholding methods (<strong>Triangle, Otsu, Mean, Li, Isodata</strong>) to handle lighting variability.</li> <li>Use <strong>connected-component labeling</strong> and select the most frequent non-background label (table assumed largest object).</li> <li>Clean masks via <strong>erosion + area opening</strong>, then compute a <strong>convex hull</strong> for each candidate table mask.</li> <li>Estimate corners using <strong>Harris corner detection</strong>. <ul> <li>If Harris fails (not exactly 4 corners), fall back to a <strong>minimum bounding rectangle</strong> on the convex hull.</li> </ul> </li> <li>Combine the 5 corner candidates using a <strong>majority vote</strong> for robustness.</li> </ul> <p><strong>Takeaway:</strong> redundancy + voting makes the table detection reliable even when some thresholding methods fail.</p> <hr> <h2 id="2-warping-and-region-splitting">2) Warping and region splitting</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0 d-flex align-items-center justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/IAPR/IAPR_2-480.webp 480w,/assets/img/projects/IAPR/IAPR_2-800.webp 800w,/assets/img/projects/IAPR/IAPR_2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/IAPR/IAPR_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Step 2 of our approach (warping and cutting of the image)" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0 d-flex align-items-center justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/IAPR/IAPR_3-480.webp 480w,/assets/img/projects/IAPR/IAPR_3-800.webp 800w,/assets/img/projects/IAPR/IAPR_3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/IAPR/IAPR_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Step 3 of our approach (splitting the table in sub-regions)" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The second (left) and third (right) steps of our pipeline: the table image is warped and cut, then it is divided in sub-regions (4 player regions, table cards region, chips region). </div> <h3 id="warping">Warping</h3> <p>Given detected table corners and a canonical destination rectangle, we estimate a <strong>projective transform</strong> and warp the image to obtain a <strong>frontal table view</strong> (both grayscale and color versions). We then crop to keep only the table.</p> <h3 id="splitting-into-sub-regions">Splitting into sub-regions</h3> <p>Because the warped table has consistent geometry, we use a <strong>hard-coded split</strong> (proportions of width/height) to extract:</p> <ul> <li>4 player regions (<code class="language-plaintext highlighter-rouge">P1..P4</code>)</li> <li>The table cards region (<code class="language-plaintext highlighter-rouge">T</code>)</li> <li>The chips region (<code class="language-plaintext highlighter-rouge">C</code>)</li> </ul> <p>We then split the table-cards region into <strong>five individual card crops</strong> (<code class="language-plaintext highlighter-rouge">T1..T5</code>), again using fixed proportional boundaries.</p> <p><strong>Takeaway:</strong> warping turns a hard detection problem into a stable “structured crop” problem.</p> <hr> <h2 id="3-chips-detection-and-classification">3) Chips detection and classification</h2> <div class="row justify-content-center"> <div class="col-sm-10 mx-auto mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/IAPR/IAPR_4-480.webp 480w,/assets/img/projects/IAPR/IAPR_4-800.webp 800w,/assets/img/projects/IAPR/IAPR_4-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/IAPR/IAPR_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Step 4 of our approach (detection and classification of chips)" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The fourth step of our pipeline: the chips are detected and classified. </div> <h3 id="detection">Detection</h3> <p>Chips are detected using the <strong>Hough circle transform</strong>, tuned to be <strong>sensitive to partially occluded circles</strong> (accepting some false positives that we later filter).</p> <p>We handle chips in two passes:</p> <ol> <li>Detect <strong>black/red/green/blue</strong> chips using the L channel thresholding strategy to separate colored chips from the table.</li> <li>Detect <strong>white</strong> chips separately (they blend with the table), using a different preprocessing path (LAB channel choice + masking) and another Hough pass.</li> </ol> <h3 id="classification-k-nn">Classification (k-NN)</h3> <p>For each detected circle:</p> <ul> <li>Build a mask for the chip interior and compute average color features.</li> <li>Use a <strong>k-NN classifier (k = 3, distance-weighted)</strong> trained on manually labeled chip samples extracted from the training images.</li> </ul> <p>Features (4D vector):</p> <ol> <li>Mean <strong>R</strong> inside chip</li> <li>Mean <strong>G</strong> inside chip</li> <li>Mean <strong>B</strong> inside chip</li> <li>Mean <strong>L</strong> over the whole chips sub-image (captures global lighting)</li> </ol> <p>We also included “negative” examples (white chips / table patches) to reject false detections.</p> <p><strong>Takeaway:</strong> circle detection + simple color features + k-NN is surprisingly strong when paired with careful preprocessing and a lighting feature.</p> <hr> <h2 id="4-card-recognition-table--players">4) Card recognition (table + players)</h2> <div class="row justify-content-center"> <div class="col-sm-10 mx-auto mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/IAPR/IAPR_5-480.webp 480w,/assets/img/projects/IAPR/IAPR_5-800.webp 800w,/assets/img/projects/IAPR/IAPR_5-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/IAPR/IAPR_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Step 5 of our approach (detection and classification of player and table cards)" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The fifth step of our pipeline: the cards (for each player and for the table) are detected and classified. </div> <h3 id="single-card-classification-table-cards">Single-card classification (table cards)</h3> <p>We implemented a <code class="language-plaintext highlighter-rouge">classify_card</code> routine based on <strong>template matching</strong>:</p> <ul> <li>Templates are extracted from provided setup images (<code class="language-plaintext highlighter-rouge">spades_suits</code>, <code class="language-plaintext highlighter-rouge">kings</code>, etc.) for: <ul> <li>Ranks: A, 2–10, J, Q, K (plus a <strong>back-of-card</strong> template for face-down cases)</li> <li>Suits: D, H, S, C</li> </ul> </li> <li>Matching metric: <code class="language-plaintext highlighter-rouge">cv.TM_CCOEFF_NORMED</code> </li> <li>For robustness to small rotations, we rotate each single-card crop from <strong>−6° to +6°</strong> (step 2°) and keep the best-confidence result.</li> </ul> <h3 id="double-card-classification-player-hands">Double-card classification (player hands)</h3> <p>Player crops contain two cards with larger rotations and mutual interference. We therefore:</p> <ul> <li>Sweep rotations from <strong>−35° to +35°</strong> (step 4°).</li> <li>Use <code class="language-plaintext highlighter-rouge">classify_double_card</code> twice per rotation: <ol> <li>Classify the best card symbol,</li> <li> <strong>Mask</strong> the matched symbol region and classify again to get the second card.</li> </ol> </li> <li>Add sanity checks: <ul> <li>Swap rank/suit if the two cards get mixed,</li> <li>Return results ordered as <strong>leftmost card first</strong>, matching the expected output format,</li> <li>Return <code class="language-plaintext highlighter-rouge">0</code> for players not playing / face-down cards.</li> </ul> </li> </ul> <p><strong>Takeaway:</strong> template matching is brittle in general, but becomes workable here thanks to controlled crops (warping) and explicit rotation search.</p> <hr> <h2 id="results-high-level">Results (high level)</h2> <p>On the provided training set, the pipeline achieved strong performance overall, with most errors coming from difficult lighting conditions, partial occlusions, or challenging suit/rank visibility:</p> <ul> <li> <strong>Chips:</strong> high accuracy (most images in the strong-score range; robust counting even with partial occlusions)</li> <li> <strong>Card ranks:</strong> very high accuracy (template matching is reliable for numbers/letters)</li> <li> <strong>Card suits:</strong> slightly harder than ranks (smaller symbols + color/lighting variability), but still strong on average</li> </ul> <hr> <h2 id="acknowledgements">Acknowledgements</h2> <p>Course: EPFL — Image Analysis and Pattern Recognition (Prof. J.-P. Thiran)<br> Team: Roberto Ceraolo, Roberto Minini, Luca Zunino</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Luca Zunino. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>